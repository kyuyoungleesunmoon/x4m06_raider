#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
X4M06 ë ˆì´ë” ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸ í˜„ì‹¤ì„± ê²€ì¦ ë„êµ¬

ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ì™€ í•˜ë“œì›¨ì–´ ë°ì´í„° ê°„ì˜ í†µê³„ì /ë¬¼ë¦¬ì  ìœ ì‚¬ì„±ì„ ë¶„ì„í•˜ì—¬
ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸ì˜ í˜„ì‹¤ì„±ì„ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python simulation_validation.py --sim-data simulation_data.h5 --hw-data hardware_data.h5
"""

import numpy as np
import h5py
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import scipy.stats
import scipy.signal
from scipy.spatial.distance import cosine
from sklearn.metrics import mean_squared_error
from pathlib import Path
import json
import argparse
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì •"""
    try:
        font_path = 'C:/Windows/Fonts/malgun.ttf'  # ë§‘ì€ ê³ ë”•
        font_prop = fm.FontProperties(fname=font_path)
        plt.rcParams['font.family'] = font_prop.get_name()
        plt.rcParams['axes.unicode_minus'] = False
    except:
        print("í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")

class SimulationValidator:
    """ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸ í˜„ì‹¤ì„± ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, sim_data_path, hw_data_path=None):
        """
        ì´ˆê¸°í™”
        Args:
            sim_data_path (str): ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            hw_data_path (str): í•˜ë“œì›¨ì–´ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        """
        self.sim_data_path = sim_data_path
        self.hw_data_path = hw_data_path
        self.validation_results = {}
        
        setup_korean_font()
        
    def load_simulation_data(self):
        """ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ"""
        try:
            with h5py.File(self.sim_data_path, 'r') as f:
                self.sim_clean = f['clean_signals'][:]
                self.sim_jammed = f['jammed_signals'][:]
                self.sim_clean_spec = f['clean_spectrograms'][:]
                self.sim_jammed_spec = f['jammed_spectrograms'][:]
            
            print(f"âœ… ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            print(f"   Clean signals: {self.sim_clean.shape}")
            print(f"   Jammed signals: {self.sim_jammed.shape}")
            return True
            
        except Exception as e:
            print(f"âŒ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_hardware_data(self):
        """í•˜ë“œì›¨ì–´ ë°ì´í„° ë¡œë“œ"""
        if not self.hw_data_path:
            print("âš ï¸  í•˜ë“œì›¨ì–´ ë°ì´í„° ê²½ë¡œê°€ ì œê³µë˜ì§€ ì•ŠìŒ")
            return False
            
        try:
            with h5py.File(self.hw_data_path, 'r') as f:
                # í•˜ë“œì›¨ì–´ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ì¡°ì •
                self.hw_clean = f['clean_signals'][:]
                self.hw_jammed = f['jammed_signals'][:]
                
            print(f"âœ… í•˜ë“œì›¨ì–´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            print(f"   Clean signals: {self.hw_clean.shape}")
            print(f"   Jammed signals: {self.hw_jammed.shape}")
            return True
            
        except Exception as e:
            print(f"âŒ í•˜ë“œì›¨ì–´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def calculate_basic_statistics(self, data, label):
        """ê¸°ë³¸ í†µê³„ëŸ‰ ê³„ì‚°"""
        return {
            'label': label,
            'mean': np.mean(data),
            'std': np.std(data),
            'variance': np.var(data),
            'skewness': scipy.stats.skew(data.flatten()),
            'kurtosis': scipy.stats.kurtosis(data.flatten()),
            'min': np.min(data),
            'max': np.max(data),
            'median': np.median(data)
        }
    
    def statistical_comparison(self):
        """í†µê³„ì  íŠ¹ì„± ë¹„êµ"""
        print("\n" + "="*60)
        print("ğŸ“Š í†µê³„ì  íŠ¹ì„± ë¹„êµ ë¶„ì„")
        print("="*60)
        
        # ê¸°ë³¸ í†µê³„ëŸ‰ ê³„ì‚°
        sim_clean_stats = self.calculate_basic_statistics(self.sim_clean, "Sim Clean")
        sim_jammed_stats = self.calculate_basic_statistics(self.sim_jammed, "Sim Jammed")
        
        # ê²°ê³¼ ì €ì¥
        self.validation_results['statistical_comparison'] = {
            'sim_clean': sim_clean_stats,
            'sim_jammed': sim_jammed_stats
        }
        
        # í•˜ë“œì›¨ì–´ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ë¹„êµ
        if hasattr(self, 'hw_clean'):
            hw_clean_stats = self.calculate_basic_statistics(self.hw_clean, "HW Clean")
            hw_jammed_stats = self.calculate_basic_statistics(self.hw_jammed, "HW Jammed")
            
            self.validation_results['statistical_comparison']['hw_clean'] = hw_clean_stats
            self.validation_results['statistical_comparison']['hw_jammed'] = hw_jammed_stats
            
            # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            clean_correlation = np.corrcoef(
                self.sim_clean.flatten()[:10000],  # ìƒ˜í”Œ í¬ê¸° ì¡°ì •
                self.hw_clean.flatten()[:10000]
            )[0, 1]
            
            jammed_correlation = np.corrcoef(
                self.sim_jammed.flatten()[:10000],
                self.hw_jammed.flatten()[:10000]
            )[0, 1]
            
            self.validation_results['correlations'] = {
                'clean_correlation': clean_correlation,
                'jammed_correlation': jammed_correlation
            }
            
            print(f"ğŸ¯ Clean ì‹ í˜¸ ìƒê´€ê³„ìˆ˜: {clean_correlation:.4f}")
            print(f"ğŸ¯ Jammed ì‹ í˜¸ ìƒê´€ê³„ìˆ˜: {jammed_correlation:.4f}")
            
            # KS í…ŒìŠ¤íŠ¸
            ks_clean = scipy.stats.ks_2samp(
                self.sim_clean.flatten()[:5000],
                self.hw_clean.flatten()[:5000]
            )
            ks_jammed = scipy.stats.ks_2samp(
                self.sim_jammed.flatten()[:5000],
                self.hw_jammed.flatten()[:5000]
            )
            
            self.validation_results['ks_tests'] = {
                'clean_ks_statistic': ks_clean.statistic,
                'clean_p_value': ks_clean.pvalue,
                'jammed_ks_statistic': ks_jammed.statistic,
                'jammed_p_value': ks_jammed.pvalue
            }
            
            print(f"ğŸ“ˆ Clean KS í…ŒìŠ¤íŠ¸: statistic={ks_clean.statistic:.4f}, p-value={ks_clean.pvalue:.4f}")
            print(f"ğŸ“ˆ Jammed KS í…ŒìŠ¤íŠ¸: statistic={ks_jammed.statistic:.4f}, p-value={ks_jammed.pvalue:.4f}")
        
        # í†µê³„ëŸ‰ ë¹„êµ í‘œ ì¶œë ¥
        self._print_statistics_table()
    
    def _print_statistics_table(self):
        """í†µê³„ëŸ‰ ë¹„êµ í‘œ ì¶œë ¥"""
        stats_keys = ['mean', 'std', 'skewness', 'kurtosis']
        
        print(f"\n{'í†µê³„ëŸ‰':<12} {'Sim Clean':<15} {'Sim Jammed':<15}", end="")
        if hasattr(self, 'hw_clean'):
            print(f" {'HW Clean':<15} {'HW Jammed':<15}")
        else:
            print()
            
        print("-" * 80)
        
        for key in stats_keys:
            sim_clean_val = self.validation_results['statistical_comparison']['sim_clean'][key]
            sim_jammed_val = self.validation_results['statistical_comparison']['sim_jammed'][key]
            
            print(f"{key:<12} {sim_clean_val:<15.4f} {sim_jammed_val:<15.4f}", end="")
            
            if hasattr(self, 'hw_clean'):
                hw_clean_val = self.validation_results['statistical_comparison']['hw_clean'][key]
                hw_jammed_val = self.validation_results['statistical_comparison']['hw_jammed'][key]
                print(f" {hw_clean_val:<15.4f} {hw_jammed_val:<15.4f}")
            else:
                print()
    
    def spectral_analysis(self):
        """ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì„± ë¶„ì„"""
        print("\n" + "="*60)
        print("ğŸµ ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì„± ë¶„ì„")
        print("="*60)
        
        # ìƒ˜í”Œ ì‹ í˜¸ì— ëŒ€í•œ PSD ê³„ì‚°
        sample_idx = 0
        
        # ì‹œë®¬ë ˆì´ì…˜ ì‹ í˜¸ PSD
        f_sim_clean, psd_sim_clean = scipy.signal.welch(
            self.sim_clean[sample_idx], 
            fs=1e6,
            nperseg=256
        )
        f_sim_jammed, psd_sim_jammed = scipy.signal.welch(
            self.sim_jammed[sample_idx],
            fs=1e6, 
            nperseg=256
        )
        
        self.validation_results['spectral_analysis'] = {
            'sim_clean_psd_peak': np.max(psd_sim_clean),
            'sim_jammed_psd_peak': np.max(psd_sim_jammed),
            'sim_clean_bandwidth': self._calculate_bandwidth(f_sim_clean, psd_sim_clean),
            'sim_jammed_bandwidth': self._calculate_bandwidth(f_sim_jammed, psd_sim_jammed)
        }
        
        # í•˜ë“œì›¨ì–´ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
        if hasattr(self, 'hw_clean'):
            f_hw_clean, psd_hw_clean = scipy.signal.welch(
                self.hw_clean[sample_idx],
                fs=1e6,
                nperseg=256
            )
            f_hw_jammed, psd_hw_jammed = scipy.signal.welch(
                self.hw_jammed[sample_idx],
                fs=1e6,
                nperseg=256
            )
            
            # ìŠ¤í™íŠ¸ëŸ¼ ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
            clean_spectral_similarity = 1 - cosine(psd_sim_clean, psd_hw_clean)
            jammed_spectral_similarity = 1 - cosine(psd_sim_jammed, psd_hw_jammed)
            
            self.validation_results['spectral_analysis'].update({
                'hw_clean_psd_peak': np.max(psd_hw_clean),
                'hw_jammed_psd_peak': np.max(psd_hw_jammed),
                'clean_spectral_similarity': clean_spectral_similarity,
                'jammed_spectral_similarity': jammed_spectral_similarity
            })
            
            print(f"ğŸ¯ Clean ìŠ¤í™íŠ¸ëŸ¼ ìœ ì‚¬ë„: {clean_spectral_similarity:.4f}")
            print(f"ğŸ¯ Jammed ìŠ¤í™íŠ¸ëŸ¼ ìœ ì‚¬ë„: {jammed_spectral_similarity:.4f}")
        
        print(f"ğŸ“Š Sim Clean PSD í”¼í¬: {np.max(psd_sim_clean):.2e}")
        print(f"ğŸ“Š Sim Jammed PSD í”¼í¬: {np.max(psd_sim_jammed):.2e}")
    
    def _calculate_bandwidth(self, frequencies, psd):
        """ìœ íš¨ ëŒ€ì—­í­ ê³„ì‚° (-3dB ëŒ€ì—­í­)"""
        peak_power = np.max(psd)
        half_power = peak_power / 2
        
        # ë°˜ì „ë ¥ ì§€ì  ì°¾ê¸°
        indices = np.where(psd > half_power)[0]
        if len(indices) > 0:
            return frequencies[indices[-1]] - frequencies[indices[0]]
        return 0
    
    def signal_quality_metrics(self):
        """ì‹ í˜¸ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°"""
        print("\n" + "="*60)
        print("ğŸ“¡ ì‹ í˜¸ í’ˆì§ˆ ì§€í‘œ ë¶„ì„")
        print("="*60)
        
        # SNR ê³„ì‚° (ê·¼ì‚¬ì¹˜)
        sim_clean_snr = self._calculate_snr(self.sim_clean)
        sim_jammed_snr = self._calculate_snr(self.sim_jammed)
        
        # ì¬ë° ëŒ€ ì‹ í˜¸ ë¹„ìœ¨
        jamming_ratio = np.mean(np.abs(self.sim_jammed)) / np.mean(np.abs(self.sim_clean))
        
        self.validation_results['signal_quality'] = {
            'sim_clean_snr_db': sim_clean_snr,
            'sim_jammed_snr_db': sim_jammed_snr,
            'jamming_ratio': jamming_ratio
        }
        
        print(f"ğŸ“Š Sim Clean SNR: {sim_clean_snr:.2f} dB")
        print(f"ğŸ“Š Sim Jammed SNR: {sim_jammed_snr:.2f} dB") 
        print(f"ğŸ“Š ì¬ë° ë¹„ìœ¨: {jamming_ratio:.2f}")
        
        if hasattr(self, 'hw_clean'):
            hw_clean_snr = self._calculate_snr(self.hw_clean)
            hw_jammed_snr = self._calculate_snr(self.hw_jammed)
            hw_jamming_ratio = np.mean(np.abs(self.hw_jammed)) / np.mean(np.abs(self.hw_clean))
            
            self.validation_results['signal_quality'].update({
                'hw_clean_snr_db': hw_clean_snr,
                'hw_jammed_snr_db': hw_jammed_snr,
                'hw_jamming_ratio': hw_jamming_ratio
            })
            
            print(f"ğŸ“Š HW Clean SNR: {hw_clean_snr:.2f} dB")
            print(f"ğŸ“Š HW Jammed SNR: {hw_jammed_snr:.2f} dB")
            print(f"ğŸ“Š HW ì¬ë° ë¹„ìœ¨: {hw_jamming_ratio:.2f}")
    
    def _calculate_snr(self, signal):
        """SNR ê³„ì‚° (ê·¼ì‚¬ì¹˜)"""
        # ì‹ í˜¸ íŒŒì›Œì™€ ë…¸ì´ì¦ˆ íŒŒì›Œ ì¶”ì •
        signal_power = np.mean(np.abs(signal)**2)
        noise_power = np.var(signal) * 0.1  # ë…¸ì´ì¦ˆ ì¶”ì • (ê°„ë‹¨í•œ ë°©ë²•)
        
        if noise_power > 0:
            snr_linear = signal_power / noise_power
            return 10 * np.log10(snr_linear)
        return float('inf')
    
    def create_validation_report(self, output_dir="validation_results"):
        """ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "="*60)
        print("ğŸ“‹ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±")
        print("="*60)
        
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True, parents=True)
        
        # JSON ë¦¬í¬íŠ¸ ì €ì¥
        report_file = output_path / "validation_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.validation_results, f, indent=2, ensure_ascii=False, default=str)
        
        # ì‹œê°í™” ìƒì„±
        self._create_validation_plots(output_path)
        
        # ì¢…í•© í‰ê°€
        overall_score = self._calculate_overall_score()
        
        # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
        text_report = output_path / "validation_summary.txt"
        with open(text_report, 'w', encoding='utf-8') as f:
            f.write("=== X4M06 ë ˆì´ë” ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸ ê²€ì¦ ë¦¬í¬íŠ¸ ===\n\n")
            
            f.write("1. ì¢…í•© í‰ê°€\n")
            f.write(f"   ì „ì²´ ì ìˆ˜: {overall_score:.2f}/100\n")
            f.write(f"   í‰ê°€ ë“±ê¸‰: {self._get_grade(overall_score)}\n\n")
            
            if 'correlations' in self.validation_results:
                f.write("2. ìƒê´€ê´€ê³„ ë¶„ì„\n")
                f.write(f"   Clean ì‹ í˜¸ ìƒê´€ê³„ìˆ˜: {self.validation_results['correlations']['clean_correlation']:.4f}\n")
                f.write(f"   Jammed ì‹ í˜¸ ìƒê´€ê³„ìˆ˜: {self.validation_results['correlations']['jammed_correlation']:.4f}\n\n")
            
            f.write("3. ê²€ì¦ ê¶Œì¥ì‚¬í•­\n")
            recommendations = self._generate_recommendations()
            for rec in recommendations:
                f.write(f"   - {rec}\n")
        
        print(f"âœ… ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_path}")
        print(f"ğŸ“Š ì¢…í•© ì ìˆ˜: {overall_score:.2f}/100 ({self._get_grade(overall_score)})")
    
    def _create_validation_plots(self, output_path):
        """ê²€ì¦ ì‹œê°í™” ìƒì„±"""
        # 1. ì‹ í˜¸ ë¹„êµ í”Œë¡¯
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ì‹œë®¬ë ˆì´ì…˜ vs í•˜ë“œì›¨ì–´ ì‹ í˜¸ ë¹„êµ', fontsize=16)
        
        # Clean ì‹ í˜¸ ë¹„êµ
        axes[0, 0].plot(np.real(self.sim_clean[0, :500]), label='Sim Clean', alpha=0.7)
        if hasattr(self, 'hw_clean'):
            axes[0, 0].plot(np.real(self.hw_clean[0, :500]), label='HW Clean', alpha=0.7)
        axes[0, 0].set_title('Clean ì‹ í˜¸ ë¹„êµ')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # Jammed ì‹ í˜¸ ë¹„êµ
        axes[0, 1].plot(np.real(self.sim_jammed[0, :500]), label='Sim Jammed', alpha=0.7)
        if hasattr(self, 'hw_jammed'):
            axes[0, 1].plot(np.real(self.hw_jammed[0, :500]), label='HW Jammed', alpha=0.7)
        axes[0, 1].set_title('Jammed ì‹ í˜¸ ë¹„êµ')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # íˆìŠ¤í† ê·¸ë¨ ë¹„êµ
        axes[1, 0].hist(np.real(self.sim_clean).flatten()[:10000], bins=50, alpha=0.5, label='Sim Clean', density=True)
        if hasattr(self, 'hw_clean'):
            axes[1, 0].hist(np.real(self.hw_clean).flatten()[:10000], bins=50, alpha=0.5, label='HW Clean', density=True)
        axes[1, 0].set_title('Clean ì‹ í˜¸ ë¶„í¬ ë¹„êµ')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        axes[1, 1].hist(np.real(self.sim_jammed).flatten()[:10000], bins=50, alpha=0.5, label='Sim Jammed', density=True)
        if hasattr(self, 'hw_jammed'):
            axes[1, 1].hist(np.real(self.hw_jammed).flatten()[:10000], bins=50, alpha=0.5, label='HW Jammed', density=True)
        axes[1, 1].set_title('Jammed ì‹ í˜¸ ë¶„í¬ ë¹„êµ')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_path / 'signal_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë¹„êµ (ì‹œë®¬ë ˆì´ì…˜ë§Œ)
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        fig.suptitle('ì‹œë®¬ë ˆì´ì…˜ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë¹„êµ', fontsize=16)
        
        im1 = axes[0].imshow(self.sim_clean_spec[0], aspect='auto', origin='lower')
        axes[0].set_title('Clean ìŠ¤í™íŠ¸ë¡œê·¸ë¨')
        plt.colorbar(im1, ax=axes[0])
        
        im2 = axes[1].imshow(self.sim_jammed_spec[0], aspect='auto', origin='lower')
        axes[1].set_title('Jammed ìŠ¤í™íŠ¸ë¡œê·¸ë¨')
        plt.colorbar(im2, ax=axes[1])
        
        plt.tight_layout()
        plt.savefig(output_path / 'spectrogram_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def _calculate_overall_score(self):
        """ì¢…í•© í‰ê°€ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        
        # ìƒê´€ê´€ê³„ ì ìˆ˜ (40ì )
        if 'correlations' in self.validation_results:
            clean_corr = self.validation_results['correlations']['clean_correlation']
            jammed_corr = self.validation_results['correlations']['jammed_correlation']
            avg_corr = (clean_corr + jammed_corr) / 2
            score += min(40, max(0, avg_corr * 40))
        else:
            score += 30  # ì‹œë®¬ë ˆì´ì…˜ë§Œ ìˆëŠ” ê²½ìš° ê¸°ë³¸ ì ìˆ˜
        
        # KS í…ŒìŠ¤íŠ¸ ì ìˆ˜ (30ì )
        if 'ks_tests' in self.validation_results:
            clean_p = self.validation_results['ks_tests']['clean_p_value']
            jammed_p = self.validation_results['ks_tests']['jammed_p_value']
            avg_p = (clean_p + jammed_p) / 2
            score += min(30, max(0, avg_p * 600))  # p > 0.05ë©´ 30ì 
        else:
            score += 20
        
        # ìŠ¤í™íŠ¸ëŸ¼ ìœ ì‚¬ë„ ì ìˆ˜ (20ì )
        if 'clean_spectral_similarity' in self.validation_results.get('spectral_analysis', {}):
            clean_sim = self.validation_results['spectral_analysis']['clean_spectral_similarity']
            jammed_sim = self.validation_results['spectral_analysis']['jammed_spectral_similarity']
            avg_sim = (clean_sim + jammed_sim) / 2
            score += min(20, max(0, avg_sim * 20))
        else:
            score += 15
        
        # ì‹ í˜¸ í’ˆì§ˆ ì ìˆ˜ (10ì )
        score += 10  # ê¸°ë³¸ì ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì´ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ
        
        return min(100, score)
    
    def _get_grade(self, score):
        """ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        if score >= 80:
            return "ìš°ìˆ˜ (A)"
        elif score >= 60:
            return "ì–‘í˜¸ (B)"
        elif score >= 40:
            return "ë³´í†µ (C)"
        else:
            return "ë¯¸í¡ (D)"
    
    def _generate_recommendations(self):
        """ê²€ì¦ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if 'correlations' in self.validation_results:
            clean_corr = self.validation_results['correlations']['clean_correlation']
            jammed_corr = self.validation_results['correlations']['jammed_correlation']
            
            if clean_corr < 0.6:
                recommendations.append("Clean ì‹ í˜¸ ëª¨ë¸ë§ íŒŒë¼ë¯¸í„° ì¬ê²€í†  í•„ìš”")
            if jammed_corr < 0.6:
                recommendations.append("ì¬ë° ì‹ í˜¸ ëª¨ë¸ë§ íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”")
        
        if 'ks_tests' in self.validation_results:
            if self.validation_results['ks_tests']['clean_p_value'] < 0.05:
                recommendations.append("Clean ì‹ í˜¸ ë¶„í¬ íŠ¹ì„± ê°œì„  í•„ìš”")
            if self.validation_results['ks_tests']['jammed_p_value'] < 0.05:
                recommendations.append("Jammed ì‹ í˜¸ ë¶„í¬ íŠ¹ì„± ê°œì„  í•„ìš”")
        
        if not recommendations:
            recommendations.append("í˜„ì¬ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸ í’ˆì§ˆì´ ì–‘í˜¸í•¨")
            recommendations.append("ì¶”ê°€ í•˜ë“œì›¨ì–´ ë°ì´í„° ìˆ˜ì§‘ì„ í†µí•œ ì§€ì†ì  ê²€ì¦ ê¶Œì¥")
        
        return recommendations
    
    def run_full_validation(self):
        """ì „ì²´ ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("\n" + "="*80)
        print("ğŸš€ X4M06 ë ˆì´ë” ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸ í˜„ì‹¤ì„± ê²€ì¦ ì‹œì‘")
        print("="*80)
        
        # ë°ì´í„° ë¡œë“œ
        if not self.load_simulation_data():
            return False
        
        if self.hw_data_path:
            self.load_hardware_data()
        
        # ê²€ì¦ ë¶„ì„ ì‹¤í–‰
        self.statistical_comparison()
        self.spectral_analysis() 
        self.signal_quality_metrics()
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        self.create_validation_report()
        
        print("\n" + "="*80)
        print("âœ… ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸ í˜„ì‹¤ì„± ê²€ì¦ ì™„ë£Œ!")
        print("="*80)
        
        return True


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='X4M06 ë ˆì´ë” ì‹œë®¬ë ˆì´ì…˜ ê²€ì¦')
    parser.add_argument('--sim-data', required=True, help='ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--hw-data', help='í•˜ë“œì›¨ì–´ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ì„ íƒ)')
    parser.add_argument('--output-dir', default='validation_results', help='ê²°ê³¼ ì¶œë ¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    # ê²€ì¦ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    validator = SimulationValidator(args.sim_data, args.hw_data)
    validator.run_full_validation()


if __name__ == "__main__":
    main()